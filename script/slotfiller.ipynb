{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "import codecs\n",
    "import subprocess\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pystruct as pystr\n",
    "\n",
    "\n",
    "import progressbar\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('slotfilling-data.json', 'r', encoding='UTF8') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    X = [item['chat'] for item in data]\n",
    "    y = []\n",
    "    for item in data:\n",
    "        entities = item['entities']\n",
    "        y_item = {}\n",
    "        for entity in entities:\n",
    "            y_item[entity['title']] = {\n",
    "                'start_pos': entity['start_pos'],\n",
    "                'end_pos': entity['end_pos'],\n",
    "                'text': entity['text']\n",
    "            }\n",
    "\n",
    "        y.append(y_item)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, ans = process_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mix the data\n",
    "perm = np.random.permutation(len(data))\n",
    "data, ans = data[perm], ans[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ВАЛЮТА',\n",
       " 'ВРЕМЯ_ДАТА_СНЯТИЯ',\n",
       " 'ЗА_ГРАНИЦЕЙ',\n",
       " 'МЕСТО_СНЯТИЯ',\n",
       " 'НАЗВАНИЕ_БАНКА',\n",
       " 'НОМЕР_ТЕЛЕФОНА',\n",
       " 'РАЗМЕР_КОМИССИИ',\n",
       " 'СУММА_СНЯТИЯ',\n",
       " 'ТАРИФ_КАРТЫ',\n",
       " 'ТИП_КАРТЫ'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_slots = set([item for y_item in ans for item in list(y_item.keys())])\n",
    "possible_slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1: Здравствуйте. У меня на дополнительной карте стоит подтверждение по подписи на чеке, я поменял на пин-код. Сказано, что теперь для подтверждения надо совершить операцию в банкомате. Какую именно?\\n2: Можете запросить баланс.\\n1: Я сегодня днем запрашивал баланс. До сих пор не подтверждено.\\n2: У Вас стоит приоритет ПИН-код.\\n1: Имеет значение, в каком банке смотреть? старом/новом\\n1: В старом сейчас стоит приоритет подписи.\\n2: Вижу, что сейчас приоритет авторизации по Вашей карте – ПИН-код. Чтобы изменения вступили в силу, нужно совершить любую операцию в банкомате (например, снимите наличные или запросите баланс). Учитывайте, что в некоторых точках оплаты у Вас могут запросить подпись. Это зависит от настроек конкретных терминалов.\\n1: Может ли зависеть от банкомата? Скажем, если запрошу баланс в другом, то в интернет-банке поменяется отображение приоритета?\\n2: Понадобится некоторое время.\\n2: Выяснила информацию, Вам нужно попробовать снять наличные в другом банкомате. Чтобы было без комиссии, сумма операции должна быть от 1111 рублей.\\n2: До 111 111 рублей.\\n',\n",
       " {})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data[0], ans[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove special symblos and lower \n",
    "def deleteExtraSymbols(line):\n",
    "    if line:\n",
    "        return re.sub(' +',' ', re.sub(r'[^А-Яа-я0-9€$ ]', u' ', line).lower().rstrip().strip())\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = []\n",
    "for dialog in data:\n",
    "    clean_data.append(deleteExtraSymbols(dialog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# лемматизация\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lem_data = []\n",
    "max_len = 0 # maximum length of the string\n",
    "for dialog in clean_data:\n",
    "    lem_dialog = ''\n",
    "    dialog_words = dialog.split(' ')\n",
    "    if len(dialog_words) > max_len: max_len = len(dialog_words)\n",
    "    for word in dialog_words:\n",
    "        p = morph.parse(word)[0]\n",
    "        lem_dialog += p.normal_form + ' '\n",
    "    lem_dialog = lem_dialog[:-1]\n",
    "    lem_data.append(lem_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Приведем ответы к виду ['О', 'О', ..., 'ИМЯ_СЛОТА', ..., 'О', 'О']\n",
    "counter = 0\n",
    "labels = []\n",
    "for i in range(len(clean_data)):\n",
    "    labels_vec = ['0'] * len(clean_data[i].split(' '))\n",
    "    for slot in possible_slots:\n",
    "        try:\n",
    "            for slot_word in deleteExtraSymbols(ans[i][slot]['text']).split(' '):\n",
    "                labels_vec[clean_data[i].split(' ').index(slot_word)] = slot\n",
    "                #print (slot)\n",
    "        except:\n",
    "            pass\n",
    "    labels.append(labels_vec)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wordList =  [[x.lower() for x in re.findall(r\"[\\w']+\", y)] for y in lem_data]\n",
    "idx2w = [] \n",
    "for dialog in lem_data:\n",
    "    for word in dialog.split(' '):\n",
    "        if not word in idx2w:\n",
    "            idx2w.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "for dialog in lem_data:\n",
    "    n_dialog = []\n",
    "    for word in dialog.split(' '):\n",
    "        n_dialog.append(idx2w.index(word))\n",
    "    #for i in range(max_len - len(n_dialog)):\n",
    "    #    n_dialog.append(10000) # padding\n",
    "    #lengths.append(len(n_dialog))\n",
    "    X.append(np.array(n_dialog))\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2la = []\n",
    "y_num = []\n",
    "\n",
    "for line in labels:\n",
    "    y_line = []\n",
    "    for slot in line:\n",
    "        if not slot in idx2la:\n",
    "            idx2la.append(slot)\n",
    "        y_line.append(idx2la.index(slot))\n",
    "    y_num.append(np.array(y_line))\n",
    "y = np.array(y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "X = sequence.pad_sequences(X, maxlen=max_len)\n",
    "y = sequence.pad_sequences(y, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = X[:6000], y[:6000], X[6000:], y[6000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN, GRU, LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xin = Input(batch_shape=(batch, timesteps), dtype='int32')\n",
    "vocab_size = len(idx2w)\n",
    "n_classes = len(idx2la)\n",
    "model = Sequential() \n",
    "model.add(Embedding(vocab_size, max_len)) # 3dim (batch,time,feat)\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_classes, activation='softmax')))            \n",
    "model.compile(loss='sparse_categorical_crossentropy',                                   \n",
    "              optimizer='rmsprop',                                               \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3650/6000 [=================>............] - ETA: 510s - loss: 0.0722 - acc: 0.9852"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train.reshape(y_train.shape[0], y_train.shape[1], 1), epochs=1, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 46s    \n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test.reshape(y_test.shape[0], y_test.shape[1], 1), batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encoding y\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit([[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])\n",
    "\n",
    "y_encoded = []\n",
    "\n",
    "for line in y:\n",
    "    y_encoded.append(enc.transform(line.reshape(line.shape[0], 1)).toarray())\n",
    "\n",
    "y = np.array(y_encoded)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
